


import numpy as np
import matplotlib.pyplot as plt # Para graficar la distribución
from scipy import stats








def pdfcdfcontinua(datos, minimo=None, maximo=None, particiones=None):
    """
    Estima la función de densidad (PDF) y la función de distribución acumulativa (CDF)
    de una muestra aleatoria `datos` usando histogramas.
    """

    datos = np.ravel(datos)
    total = len(datos)

    if minimo is None or maximo is None:
        rango = np.max(datos) - np.min(datos)
        minimo = np.min(datos) - 0.02 * rango
        maximo = np.max(datos) + 0.02 * rango

    print(minimo, maximo)

    if particiones is None:
        particiones = int(np.floor(np.sqrt(total)))

    bins = np.linspace(minimo, maximo, particiones + 1)

    # Histograma normalizado (densidad=True) para obtener PDF
    fr, edges = np.histogram(datos, bins=bins, density=False)
    ancho_bin = edges[1] - edges[0]
    pdf = fr / (total * ancho_bin)

    # CDF como suma acumulativa de las frecuencias normalizadas
    cdf = np.cumsum(fr) / total

    x = edges[:-1] + ancho_bin / 2  # Coordenadas del centro de cada bin

    # Gráficas
    fig, axs = plt.subplots(2, 1, figsize=(8, 6))

    axs[0].plot(x, pdf, linewidth=2)
    axs[0].set_title("Estimación de la función de densidad")
    axs[0].set_xlabel("$x$")
    axs[0].set_ylabel("$f_X(x)$")
    axs[0].grid(True)

    axs[1].plot(x, cdf, linewidth=2)
    axs[1].set_title("Estimación de la Distribución Acumulativa")
    axs[1].set_xlabel("$x$")
    axs[1].set_ylabel("$F_X(x)$")
    axs[1].grid(True)

    plt.tight_layout()
    plt.show()

















# Parámetros de la distribución uniforme discreta
valor_minimo = 1
valor_maximo = 6
numero_de_muestras = 10000


muestras = np.random.randint(valor_minimo, valor_maximo + 1, size=numero_de_muestras)


print(f"Algunas muestras generadas (primeras 20): {muestras[:20]}")
print(f"Valor mínimo generado: {np.min(muestras)}")
print(f"Valor máximo generado: {np.max(muestras)}")


# Calcular la frecuencia de cada número
valores_unicos, conteos = np.unique(muestras, return_counts=True)
for valor, conteo in zip(valores_unicos, conteos):
    print(f"Valor: {valor}, Frecuencia: {conteo}, Probabilidad estimada: {conteo/numero_de_muestras:.4f}")


# Graficar el histograma de las muestras para visualizar la distribución
plt.figure(figsize=(8, 5))
plt.bar(valores_unicos, conteos, width=0.9, color='skyblue', edgecolor='black')
plt.xlabel("Valor")
plt.ylabel("Frecuencia")
plt.title(f"Distribución Uniforme Discreta ({numero_de_muestras} muestras)")
plt.xticks(range(valor_minimo, valor_maximo + 1)) # Asegurar que todos los valores del rango aparezcan en el eje x
plt.grid(axis='y', linestyle='--')
plt.show()



def _pendienteci(x, y):
    """
    Regresión lineal simple (mínimos cuadrados) y cálculo de intervalo de confianza al 95% para la pendiente.

    Parámetros
    ----------
    x : 1D array
        Variable independiente (log10(m)).
    y : 1D array
        Variable dependiente (log10(varianza)).

    Devuelve
    -------
    m : float
        Pendiente de la recta.
    b : float
        Ordenada al origen de la recta.
    ml : float
        Límite inferior de intervalo de confianza (95%) para m.
    mh : float
        Límite superior de intervalo de confianza (95%) para m.
    """
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    n = x.size
    if n < 3:
        raise ValueError("Se requieren al menos 3 puntos para realizar regresión.")

    # Cálculo de parámetros de la recta: m y b
    A = np.dot(x, x)
    B = x.sum()
    C = np.dot(x, y)

    x_mean = x.mean()
    y_mean = y.mean()

    m = (C - B * y_mean) / (A - B * x_mean)
    b = y_mean - m * x_mean

    # Error residual
    y_pred = m * x + b
    error = y - y_pred
    s = np.sqrt(np.dot(error, error) / (n - 2))

    # Sxx = sum((x - x_mean)^2)
    ex = x - x_mean
    Sxx = np.dot(ex, ex)

    # t critico para 95% en n-2 grados de libertad
    tval = stats.t.ppf(0.975, df=n - 2)

    # Intervalo de confianza para la pendiente m
    ml = m - tval * s / np.sqrt(Sxx)
    mh = m + tval * s / np.sqrt(Sxx)

    return m, b, ml, mh

def vt(traza):
    """
    Diagrama Varianza–Tiempo y estimación del parámetro de Hurst.

    Parámetros
    ----------
    traza : array_like, 1D
        Vector de datos (serie de tiempo) sobre el cual se calcula el diagrama varianza–tiempo.

    Devuelve
    -------
    H     : float
        Estimación del parámetro de Hurst (punto medio de la recta).
    Hmin  : float
        Límite inferior del intervalo de confianza al 95% para H.
    Hmax  : float
        Límite superior del intervalo de confianza al 95% para H.

    Además, la función dibuja (en pantalla) el diagrama log10(varianza) vs. log10(m)
    junto con la recta de regresión lineal y su intervalo de confianza.
    """
    traza = np.asarray(traza).flatten()
    L = traza.size

    # gruposmax = fix(L / sqrt(L)) en MATLAB equivale a floor(sqrt(L))
    gruposmax = int(np.floor(np.sqrt(L)))
    if gruposmax < 2:
        raise ValueError("La longitud de 'traza' es demasiado pequeña para calcular vt().")

    # Reservamos un arreglo para varianza; tendrá longitud (gruposmax - 1)
    varianza = np.zeros(gruposmax - 1, dtype=float)

    # Para cada n = 2 ... gruposmax, calculamos:
    #   columnas = fix(L / n)
    #   datos  = reshape(traza(1 : n*columnas), [n, columnas])
    #   varianza(n-1) = var(promedios), donde promedios = mean(datos) (promedio por columna)
    for idx, n in enumerate(range(2, gruposmax + 1)):
        columnas = int(np.floor(L / n))
        if columnas < 1:
            # si columnas=0, no podemos reshape; salir del bucle
            break

        # Reproducimos reshape(..., [n, columnas]) de MATLAB (que rellena por columnas).
        bloque = traza[: n * columnas]
        datos = bloque.reshape((n, columnas), order='F')

        # promedio de cada columna (dim=0) y varianza muestral (ddof=1)
        promedios = datos.mean(axis=0)
        varianza[idx] = np.var(promedios, ddof=1)

    # Tomamos sólo los índices válidos (en caso de que el bucle se haya roto antes)
    Npts = idx + 1
    varianza = varianza[:Npts]

    # Construimos x = log10(m) para m = 2,3,...,2+Npts-1
    m_vals = np.arange(2, 2 + Npts)
    x = np.log10(m_vals)
    y = np.log10(varianza)

    # Regresión lineal con intervalo de confianza
    m_slope, b_intercept, ml, mh = _pendienteci(x, y)

    H     = m_slope / 2 + 1
    Hmin  = ml / 2 + 1
    Hmax  = mh / 2 + 1

    # --- Visualización del diagrama ---
    fig, ax = plt.subplots(figsize=(8, 5))
    # Puntos experimentales
    ax.plot(x, y, 's', markerfacecolor='b', markeredgecolor='k', label=r'$\log S_{X^{(m)}}^2$')

    # Recta de regresión: y_hat = m_slope * x + b_intercept
    y_hat = m_slope * x + b_intercept
    ax.plot(x, y_hat, 'r', linewidth=2, label='Regresión Lineal')

    # Intervalo de confianza (líneas punteadas)
    xmin, xmax = x.min(), x.max()
    ymin, ymax = y.min(), y.max()

    # Definimos x1, x2 tal como en MATLAB (0.45 y 0.55 del rango)
    x1 = xmin + 0.45 * (xmax - xmin)
    x2 = xmin + 0.55 * (xmax - xmin)
    y1 = m_slope * x1 + b_intercept
    y2 = m_slope * x2 + b_intercept

    # Dibujamos: una línea vertical en x = x1 desde y1 hasta y2, y luego la horizontal en y = y2 de x1 a x2
    ax.plot([x1, x1, x2], [y1, y2, y2], 'k:', linewidth=2)

    # Ajustes estéticos
    ax.set_title('Diagrama Varianza - Tiempo', fontsize=18)
    ax.set_xlabel(r'$\log m$', fontsize=18)
    ax.set_ylabel(r'$\log S_{X^{(m)}}^2$', fontsize=18)
    ax.grid(True)
    ax.set_xlim(xmin, xmax)
    delta_y = ymax - ymin
    ax.set_ylim(ymin - 0.1 * delta_y, ymax + 0.1 * delta_y)
    ax.tick_params(labelsize=16)
    ax.legend(loc='best', fontsize=14, frameon=False)
    fig.patch.set_facecolor('white')

    plt.show()

    return H, Hmin, Hmax




x, hmin, hmax =  vt(muestras)


print(x)
print(hmin)
print(hmax)



